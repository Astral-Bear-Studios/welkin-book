% SPDX-FileCopyrightText: 2023 Oscar Bender-Stone <oscarbenderstone@gmail.com>
% SPDX-License-Identifier: CC-BY-4.0
% 4-spec.tex - Specifices the Welkin language and provides a theoretical framework
% for general implementations


\chapter{The Welkin Standard}

\section{Preliminaries}

% Helpful macros for terms for character encoding in math mode
\newcommand*{\chars}{\mathrm{CHAR}}
\newcommand*{\bytes}{\mathrm{BYTES}}
\newcommand*{\numbers}{\mathrm{NUMBER}}
\newcommand*{\term}{\mathrm{term}}

\subsection{Character Encodings}
% TODO: generalize to byte encodings and numbers.
In a formalist fashion, our BNF variant leaves encodings as an generalized notion. Let Char be an arbitrary, finite set.
An \textbf{encoding} is a mapping $E : \mathbb{N} \to \chars.$
We denote $\chars = E(\chars)$ and CHAR* as the Kleene-closure of CHAR. Moreover there is a distinguished subimage $\numbers \subset chars.$ Character encodings may be given as finite tables. Several major encodings are formally defined in the following sources.
\begin{itemize}
	\item ASCII []
	\item UTF-8 []
	\item UTF-16
\end{itemize}

\subsection{EBNF Variant}
Our variant of EBNF uses the following notation:
\begin{itemize}
	\item Rules are optionally surroudned in angular brackets $<term>;$
	\item $::=$ denotes rule assignment. Any rule ending in $CHAR*$ or $NUMBER*$ means the rule is a member of $CHAR*,$ $NUMBER*,$;
	\item $|$ denotes alternation;
	\item $\term*$ means 0 or more instances and is a shorthand for the rule $terms ::= term terms | term | \varepsilon;$
	\item $\term?$ means at most one instance and is a shorthand for the rule $terms ::= term | \varepsilon;$
	\item Single quotes denote a string in CHAR*. In thesse strings are double or single quotes in CHAR*, the notation [\``] or ['] is used, resectively, to avoid confusion.
\end{itemize}

% \begin{itemize}
% 	\item While there is an ISO standard for EBNF, several authors have noted it has issues. References: \url{https://dwheeler.com/essays/dont-use-iso-14977-ebnf.html}, \url{https://www.grammarware.net/text/2012/bnf-was-here.pdf}. As recommended by David Wheeler in the first reference, we use the BNF Notation defined in the W3 standard (at \url{https://www.w3.org/Notation.html}).
% \end{itemize}
\section{The Welkin Language}

There are two fundamental variants of Welkin:
\begin{itemize}
<<<<<<< HEAD:chapters/3-spec.tex
	\item First Define character encodings in general. Helpful reference: \url{https://www.w3.org/International/questions/qa-what-is-encoding}
	      \begin{itemize}
		      \item For wide spread use, there should be \textit{access to} different character encodings used for \textit{direct comparison} with Welkin files. Ultimately, every Welkin file will be converted into a standard binary (or possibly text) file to store the contents of a welkin file
	      \end{itemize}
	\item Nearly Complete: Determine a suitable BNF for Welkin, which can be parsed with LALR (or otherwise a more efficient parser). This has been chosen to use a minimal grammar that can represent graphs and connections. (Technically, as we will note, only graphs are needed, OR connections; by Foci-Continuum duality, they can be derived from one another. To make this duality more explicit in the enoding, however, the minimal grammar will stick to using both).
	      \begin{itemize}
		      \item For most cases, the full (lalr) parsing option will be used and will be the default. As an experimental component, regexes \textit{can} be calculated, in case there is a known level of nesting that will be used in a Welkin file. (This is siginificantly more complicated with the prescece of custom grammars, but that is discusses later). There will be two variants for parsing: the finite (regex) and full versions.
		            \end{itemize}
		      \item The standard format should read just like an ordinary programming language. It may be akin to graphviz, but it should prioritze on the contents of each node and edge, not necessarially how they are rendered. (I have been thinking about how we make a direct interafce for rendering these edges, and for creating custom grammars. For that, see the subsection on Interfaces)
		            \begin{itemize}

			            \item Welkin essentially needs the key elements from set theory: conjunction, disjunction, negation, implication, etc. We can actually express the first two using graphs alone (and conjunctions are an easier way to write graphs consisting of three items, and conversely, graphs are an easier way to exhibit relatively loose connections. Work still needs to be done on negation, however). We can use corresponding symbols for these: $\&\&, ||, \neg, \rightarrow$. In \textit{customizable files}, these symbols can be overloaded and added upon.
			            \item Key goal: make this FULLY compatible with dot. (In fact, for a prototype, we can work with dot directly, but we should make it helpful for our needs).
									\item Another important point: we want to say that graph ALWAYS refers to a metagraph (to avoid redundancy)		            \end{itemize}
	\item Following CFLT, explain a suitable semantics for Welkin.
	      \begin{itemize}
		      \item We need to determine how to \textit{define} all of the axioms. (In order to actually run these axioms, we need a Turing complete programming language. But for that, we need a suitable interface protocol. Programming languages can be extremely messy and difficult to work with, so how can we make a general and long-term interface?)
			\item We also need to use a suitable proof system (e.g., Hilbert, Gentzen, etc.). Maybe that could be decided in CFLT?
			\item It may significantly be easier to allow overloading terms. At the end of the day, as long as a Welkin Information Graph is produced, the process to \textit{get there} is in the hands of the user. They can use Welkin, or they can do the work themselves.
	      \end{itemize}
=======
	\item Base Welkin, a language mirroring the core data structures;
	\item Standard Welkin, which extends Base Welkin with attributes. These attibutes can alter or customize the interpreter's behavior.
>>>>>>> origin/main:chapters/4-spec.tex
\end{itemize}
Both can be parsed with LALR parsers and fundamentally have the same semantics.

% \begin{itemize}
% 	% \item First Define character encodings in general. Helpful reference: \url{https://www.w3.org/International/questions/qa-what-is-encoding}
% 	%       \begin{itemize}
% 	% 	      \item For wide spread use, there should be different character encodings used for \textit{direct comparison} with Welkin files. Ultimately, every Welkin file will be converted into a standard binary (or possibly text) file to store the object
% 	%       \end{itemize}
% 	\item Determine a suitable BNF for Welkin, which can be parsed with LALR (or otherwise a more efficient parser)
% 	      \begin{itemize}
% 		      \item Key goal: make Welkin's syntax fully decidable and efficient to parse. An important component of CFLT called the Semantics Lifting Lemma (TBD) essentially says we can embed a complex syntax into a semantics. (This proof will hopefully be constructive and work for any random syntax, no matter how crazy it might be). In other words, using an efficient parser does NOT limit how expressive Welkin is.
% 		      \item Presuming the result above, there will be two variants: the finite (regex) and full versions.
% 		            \begin{itemize}
% 			            \item The finite, or regex, version is purely for regex-definable files.
% 			            \item The full version will be LALR parsed, as it is generally a standard for programming languages. Not only is it efficient (both in speed and memory), but any grammar written in LALR is unambiguous (reference needed!).
% 			            \item Now that the idea of these two versions is solidifed, we need some common terms. Most of these should come from graphviz, but also in other note taking formats.
% 		            \end{itemize}
% 		      \item The standard format should read just like an ordinary programming language. It may be akin to graphviz, but it should prioritze on the contents of each node and edge, not necessarially how they are rendered. (A better thought would be to put rendering information in a standard \textit{library}, which could then be minimized when browsing through a Welkin file/project.)
% 		            \begin{itemize}
% 			            \item Welkin essentially needs the key elements from set theory: conjunction, disjunction, negation, implication, etc. We can use corresponding symbols for these: $\&\&, ||, \neg, \rightarrow$. In \textit{customizable files}, these symbols can be overloaded and added upon.
% 			            \item Key goal: make this FULLY compatible with dot. (In fact, for a prototype, we can work with dot directly, but we should make it helpful for our needs).
% 									\item Another important point: we want to say that graph ALWAYS refers to a metagraph (to avoid redundancy)		            \end{itemize}
% 	      \end{itemize}
% 	\item Following CFLT, explain a suitable semantics for Welkin.
% 	      \begin{itemize}
% 		      \item We need to determine how to implement all of the axioms.
% 		      \item We also need to use a suitable proof system (e.g., Hilbert, Gentzen, etc.). Maybe that could be decided in CFLT?
% 	      \end{itemize}
% \end{itemize}
% TODO: figure out how to handle references to self. Is a separate keyword 'self' needed?
%\renewcommand{\syntleft}{\normalfont\bfseries}
%\renewcommand{\syntright}{}

% TODO: directly convert this into other grammars, such as lark.
% There should be some consistent procedure to ensure that the BNF here
% is the same as those found in any implementation
% Interesting idea: when there is a node A that should connect to other nodes B_1, B_2, ..., B_n,
% we require that the latter nodes be wrapped in their own graph. That way, we can stay consistent with
% GraphViz notation (for possible compatiblity reasons), but at the same time, we can keep track of the out-neighbors (out going
%\renewcommand{\bnfexpr}{\textbf}
\subsubsection*{Syntax}
\begin{bnfgrammar}
	terms ::= term*
	;;
	term ::= graph || connection || ident || string || num ;;
	graph ::= <graph ident>? `\{' terms `\}';;
	<graph ident> ::= ident || string ;;
	connection ::= term connector term ;;
	connector ::= edge | <left arrow> | <right arrow> ;;
	edge ::= `-' term `-' ;;
	<left arrow> ::= `-' term `->' ;;
	<right arrow> ::= `<-' term `-' ;;
	ident ::= CHAR* ;;
	num ::= NUMBER* ;;
	string ::= [``] CHAR\* [''] || [`] CHAR\* [']
\end{bnfgrammar}


% TODO: the slashes quotes above should be slashes, and then quotes. We need to fix this!
Base Welkin is given by the grammar in Figure ??. Note that if $\numbers= \emptyset,$ any instances of the rule num must be excluded from the parser. This grammar defines the text-based interface to the Welkin Information Graph (see Subsection 2.? for more details). Implicitly while parsing, we enforce the fact that all identifiers may not solely contain the symbols $\{, \}, --, ->, \text{or} <-.$ We enforce this by matching these symbols first.
% TODO: recognize, in cflt, that the above welkin file is in fact a context free grammar! The more important part, which we need to still define, is the semantics, which will have its full strength with the full grammar. (Maybe we should change that option to be semantics instead?)

<<<<<<< HEAD:chapters/3-spec.tex
\subsection{Standard Grammar}
The standard grammar is provided in Figure ?.?.
\begin{bnfgrammar}
	term ::= (import || graph || connection || list || tuple || operator|| atom)*;;
	import ::= ``import'' ident
	graph ::= (ident | string)? `\{' term `\}';;
	connection ::= term connector term;;
	connector ::= edge || arrow;;
	edge ::= `-' term `-';;
	arrow ::= `-' term `>' || `<' term `-';;
	atom ::= self || ident || string;;
	self ::= ``~self''
	ident ::= CHAR*;;
	string ::= [``] CHAR* [''] || [`] CHAR* [']
\end{bnfgrammar}
=======
\subsubsection*{Semantics}
A \textbf{scope} is recursively defined and intutively is a level of terms. A \textbf{valid} base Welkin file consists satisfies a unique naming rule: in every scope, there are no name collisons. In particular, every graph must \textbf{only be defined once.}
\\ We first form an Abstract Syntax Tree (AST), from which we form the final stored data in a \textbf{Encoded Welkin Information Graph.}
\begin{definition}
  Base Welkin is parsed into the following AST $\mathcal{A}.$
  \begin{itemize}
	\item Every term is a new subtree with its contents as children.
    \item Every graph is an ordered pair of its alias and list of children
    \item Every connection
		  \begin{itemize}
			\item Left arrows
			\item Right arrows
			\item Edges define both a left and right arrow
		  \end{itemize}
	\item Every atom is converted into its corresponding encoding via the function $\mathcal{B} : \chars \to \bytes$
\end{itemize}
 \end{definition}
% TODO: talk about encoding of numbers. This probably a separate encoding from the one used to write the welkin file
\begin{definition}
	A \textbf{Welkin Information Graph (WIG)} is a tuple $G = (V, E, A),$ where
	\begin{itemize}
		\item $V$ is a set of \textbf{vertices} or \textbf{units,}
		\item $E \subseteq V^{2} $ is a set of \textbf{(directed) edges,}
		\item $A: \chars* \to V \cup E$ is an \textbf{alias function.}
	\end{itemize}
  \end{definition}
  Notice that not every vertex or edge in a WIG have an alias, as opposed to a colored graph. There are several examples demonstrating that, under a suitable transformation, a normalized WIG may contain new structures not found in a Welkin file. See Example ??.
\begin{lemma}
The conversion from ASTs to Welkin Information Graphs is valid.
\end{lemma}
The final output of parsing is a normalized WIG. We define Welkin Normal Form in the following fashion.
>>>>>>> origin/main:chapters/4-spec.tex


Based on this form, we have chosen a unique way to represent Welkin . In particular, there is a representation under WIG (generalized) homotopies. We prove that there is a polynomial (or exponential?) algorithm to convert any WIG into its corresponding representation via WNF.
\\ See section ``Graph Application Behavior'' for more details. For subsequent chapter, we refer to the file above as \textbf{-config.}


\section{General Application Behavior}


\subsection{Customization}
All Welkin files are infinitely customizable via the welkin config file, which is written in standard welkin.

Every .welkin file has a corresponding configuration. It may either be put as a comment or (preferred) written in a separate file, which, by default, is called config.welkin. It has the following format:
% TODO: replace itemzie with listing
% TODO: decide how to work with a folder (or folders) of config files
\begin{itemize}
	\item Encoding
				\begin{itemize}
					% TODO: list major ascii versions/varieties. Need an official reference for this!
					\item Options: ascii, utf-8, utf-16, other
					\item In the case of other: we need to specify how to define an encoding. (We need a light-weight API for implementations)
				\end{itemize}
	\item Grammar
				\begin{itemize}
					\item Strength: bounded (only finitely nested graphs with a given nesting limit, no recursion), no-self (arbitrary nesting limit, but no recursion), full (recursion allowed)
					\item Customized: use a builtin template or custom welkin file. These can be used to change any part of the grammar, including adding keywords, the symbols used, adding new symbols, etc. Essentially, this will be a way to built new grammars from the original specification; we will need a separate parser for this (i.e., a parser of BNF/Welkin accepted notation).
				\end{itemize}

	\item (Optional) Language
				\begin{itemize}
					\item Defaults to English. Can be written in the writer's desired language (as long as it has been configured in Encoding above)
				\end{itemize}
\end{itemize}

Alternatively, a file with a different name may be used; see th


<<<<<<< HEAD:chapters/3-spec.tex
\begin{itemize}
	\item Current problem: we need a way to recognzie which Welkin modules (graphs) define grammars. (Then we can figure out how one can customize \textit{any} aspect of Welkin). Here are some possible solutions (and evaluations thereof):
				\begin{itemize}
					\item Introduce a new meta-arrow \texttt{=>} designed specifically to be detected by Welkin (the left hand side denotes any terms in the user file; the right hand side must be terms that are defined by the Welkin interface). Using this symbol may initially work, but what if a user would like to use this meta-arrow in their grammar? How do we control how much the meta-arrow is used? I feel as though this could be dangerous, if not managed. Moreover, logistically, \textit{how} do we inform users of the terms they may bind to? For example, in the long-term, how do we make it clear that there is a ident for, say, num (standing in for general int/float)?
					\item Create a different welkin file, such as welkin.config, that only uses minimal syntax (or a slightly extended version). This would ensure that there is a distinction between the information in welkin files and the grammars that they utilize. However, we want to makek Welkin infinitely customizable, so I aim not to use this solution, if at all possible.
					\item Preferred, but still in the works: bootstrap interfaces. We would probably want to add this subsection later on, but definitely mention it while customizing grammars. \textit{Actually, customizing grammars is NOT a part of the standard, but rather, it is a part of the API. We will include EBNF and the custom grammar for standard Welkin}
				  \item I am aiming to use the last solution, but what should the standard Welkin language be? Should it be aimed for programmers? Should it be aimed for general information preservation?
				\end{itemize}
	\item At this point, I believe I am aiming to use the first solution; it would be benefitcial for Welkin itself to intrepret what Welkin files do, not \textit{directly} the other way around. At its core, Welkin files store information; it is up to an external program (such as Welkin) to figure out \textit{how} those files may be interpreted.
				\begin{itemize}
					\item Moreover, doing the other way around directly would prove formally difficult. For correctness, we would have to worry about having a correct model for C, the operating system, etc.. But, part of this project is building the infrastructure for \textit{getting and organizing} that specification! For initial implementations, Welkin need not \textit{have} a low-level specification, so neither should this standard. That should be taken care of in a formally verified programming language (or formally verified binaries).
					\item I hope that using the meta arrow could be optional in time; there could easily be ambigiuity if
								care is not taken. For example, the rule (test1 -> test2 -> graph) is ambiguous because of the ordering of the parantheses; it is unclear what is ultimately turned into a rule.
					\item However, if the lefthand side only uses terms in the minimal grammar, this would not be ambigiuous. That could certainly work. Regardless, \textit{we need to make it clear HOW Welkin, the program, is involved. Using the meta arrow is probably the least intrustive way to go about this, and can easily be customized by the user.}
				\end{itemize}

  \item Rephrasing above problem: how do we make it clear when we are defining a new semantics?
		\begin{itemize}
		  \item A key realization: Welkin \textit{is a semantics language.} You can define anything in it! It suffices to show that we can embed Welkin into discrete foci (or, more directly, can define any Chomsky grammars. This part is pretty clear from the semantics given to base welkin (or for graphs, and for connections, not for a reference to self + ?))
		  \item We could try making code blocks that specifically contain bindings. This would be a fancier alternative to restricting names (or coming up with a system, such as names prefixed with $_{}$). My hesitance to go with this solution is flexibility; should we force the users to do this?
		  \item Here is a possible question we can ask: how do we distinguish between regular and \textit{interfaced} Welkin?
		  \item The goal is to have the \textit{guest} tackle how to interpret Welkin... but we still want to put the guest in Welkin!
				\begin{itemize}
				  \item How do we gain ``awareness'' about Welkin's interfaces?
				  \item We need a place to talk about \textit{interpretations.} We know Welkin can talk about it, but how do we \textbf{reference external things? (Files, programs, even a simple microcontroller?)}
						\begin{itemize}
						  \item Do we directly include a pointer to the file? Is that strictly necessary8? It could definitely break on different machines. We would have to keep some config data in mind.
						  \item We know that any possible import symbols, as per compiler theory (and general humanb comprehension) need to be applied directlyat the \textit{top} of a page. But how do we define the import statement itself?
						  \item Can we bootstrap an interface mechanism?
						\end{itemize}
				\end{itemize}
		\end{itemize}

  \item Current (recommended) solution: we define standard Welkin to have direct access to the interpreter, similar to prolog. \textit{Later on, we will make it clear that standard Welkin can be queries, but can do more.} Ultimately, \textit{it is up to the individual to decide whether they include programming elements into their own welkin files. This is the key thing! } All the user needs to do is define their EBNF in standard Welkin
		\begin{itemize}
		  \item Here's a big idea: we can go back and \textit{refine} the base interface through standard Welkin! That's the powerful of Welkin, after all!
		  \item More precisely, we need to implement Vero, the Welkin interface for stating and verifying formal properties. \textit{We only want to make this through the APIs specified by Welkin. The implementation should NEVER matter for verification.}
		  \item There should be a separate document outling the thought process behind Vero, but for the most part, Vero should be defined \textit{with Welkin alone.} It will be the big first test for Welkin to make sure Welkin's claim for any layer of abstraction works well.
		\item Vero comes with its own grammar which is fully customizable (some mathematicians/logicians/etc may want to change it, for their personal preference). We also have certain semantics that impose checks on graphs. This is the key thing here: \textit{we want to make checks/formal properties explicit.}
		  \item Main takeaway: \textit{the interface can always be defined first. It need not be perfect. We can start with any interface and clarify it with Welkin. We can delete things, but we NEVER have to. We can add onto it instead}
		  \item Moreover, using standard Welkin for \textit{all implementations} is a good sanity check; how can we check different configs with completely different grammars! At some point, \textit{ we need to use the same language to customize things!} Starting with this idea, it is straight forward to make custom interpreter settings \textit{in your own language.} You just have to invoke it in standard welkin at some point.
				\begin{itemize}
				  \item In fact, some core plugins will use this idea as well! One of the big things to have is a suitable \textit{build system.} That will be included and have a straightforward interface.
				  \item Other key starter grammars include: bullets (for bullet point type notes) and literate (for a starting point with code blocks). (As an implementation detail, these should be \textit{optional} packages the user can be install; they should be more straightforward to get setup)
				\end{itemize}
		\end{itemize}


\end{itemize}

In Welkin, we informally write the BNF above as follows:
% TODO: explain unit notation (as it maybe clearer than the recursion below). In other words, mark arbitrary variables with the keyword unit
% TODO: decide whether to introduce another arrow symbol for custom grammars.
% While we have imposed few to no restrictions on custom grammars (besides being LALR), it may be the case
% that multiple people want to use => for their own purpose. Is there a convenient way we can do this?
=======
>>>>>>> origin/main:chapters/4-spec.tex
\begin{quote}{\ttfamily \raggedright \noindent
	term -> \{ graph connection ident string\}\\
	graph -> \{\{ident \{\}\}->`\{'--term--`\}'\}\\
	connection -> \{term--connector--term\}\\
	connector -> \{edge arrow\}\\
	edge -> `--'\\
	arrow -> `->'\\
	ident -> CHAR*\\
	string -> ``'' CHAR* ``'' | `\`' CHAR* `\''
}\end{quote}

\section{Core Algorithms}

\subsection{Graph Encoding}



\label{ch:spec}
