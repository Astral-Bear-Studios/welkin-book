% SPDX-FileCopyrightText: 2023 Oscar Bender-Stone <oscarbenderstone@gmail.com>
% SPDX-License-Identifier: CC-BY-4.0
% 4-spec.tex - Specifices the Welkin language and provides a theoretical framework
% for general implementations

% TODO: create a version for welkin-standard.tex that directly includes the copyright notice
% Henceforth, compliant Welkin implementations will be collectively referred to as ``Welkin.'' A formal definition of

We now provide the full specification of the Welkin language. Everything beyond this paragraph is included in the official welkin-standard.pdf, available at \url{https://github.com/AstralBearStudios/welkin-book/}. Note that the entire standard, including its references, is self contained.


This standard requires a cursory background in discrete mathematics and Context Free Grammars. A reading of [] and [] suffices to understand this document.

\section{Preliminaries}

% Helpful macros for terms for character encoding in math mode
\newcommand*{\chars}{\mathrm{CHAR}}
\newcommand*{\numbers}{\mathrm{NUMBER}}
\newcommand*{\whitespaces}{\mathrm{WHITE\_SPACES}}
\newcommand*{\reserved}{\mathrm{RESERVED}}
\newcommand*{\strings}{\mathrm{STRING}}
\newcommand*{\term}{\mathrm{term}}
\newcommand*{\terms}{\mathrm{terms}}
\newcommand*{\delimiters}{\mathrm{DELIMITERS}}
\newcommand*{\encoding}{\mathcal{E}}
\newcommand*{\decoding}{\mathcal{D}}

\newcommand*{\scope}{\textrm{scope}}

\subsection{Character Encodings}
% TODO: generalize to byte encodings and numbers.
In a formalist fashion, we define text, character encodings, and character decodings as generalized notions. The discussion here may be carried out with bytes and specific data formats, but these concepts are beyond the scope of this standard.

Let Char be an arbitrary, finite set. An \textbf{encoding} is an injective mapping $\encoding : \mathbb{N} \to \textrm{Char}.$ The associated \textbf{decoding} is the left-inverse $\decoding: \mathrm{Char} \to \mathbb{N}$ of $\encoding.$ There is a natural extension $\decoding^{*}: \textrm{Char}^{*} \to \mathbb{N}^{*}$
that maps sequences in Char pointwise to sequences in $\mathbb{N}^{*}.$

Character encodings may be given as finite tables, matching natural numbers with characters. Several major encodings are formally defined in the following sources.
\begin{itemize}
	\item ASCII []
	\item UTF-8 []
	\item UTF-16 []
\end{itemize}

We denote $\chars = \decoding(\chars)$ and CHAR* as the
Kleene-closure of CHAR, whose elements are called \textbf{words.}
\footnote{Traditionally, the Klenne-closure of a set $A$ is denoted by $A^{*}.$ However, to ensure our BNF
can be written in pure ASCII, we append $*$ without a superscript on $\chars$ and its subsets.}
We recognize distinguished (possibly empty) subimages $\numbers, \whitespaces \subset \chars,$ as well as a set $\delimiters \subset \chars^{2}.$ A $\textbf{string}$ $s$ is a word such of the form
\begin{align*}
s = d_{1}ud_{2} \\ (u \in \chars \setminus \delimiters, (d_{1}, d_{2}) \in \delimiters^{2}).
\end{align*}
We call $u$ the \textbf{contents} of $s.$ We define $\strings := \strings(\delimiters)$ as the set of strings over $\delimiters.$ Strings may include their delimiters by escaping them, i.e., using a different or suffix DELIMITER\_ESCAPE.

Every standard Welkin grammar is written in ASCII, but the interpreter may support additional encodings. (See Section ?.?).

We implicitly assume that $\chars*$ does not conflict with literals defined in a given standard grammar. In terms of the recommended LALR parser, this means that literals are matched first, not identifiers containing those characters. However, these characters may creating a custom grammar (see Section ?).


\subsection{EBNF Variant}
Our variant of EBNF uses the notation in Table ?.?.
\begin{center}
\begin{tabular}{ | m{3cm} | m{5cm} | m{5cm} | }
	\hline
  Concept & Notation & Example \\
  \hline
	Rule Assignment & $=$ & $term = atom$\\
  Empty String & $\varepsilon := \emptyset \in \chars*$ & $term = \varepsilon$ \\
  Concatenation (No white space) & ``.'' & \\
  \hline
\end{tabular}
\end{center}
Each BNF has an associated subset $\reserved \subseteq \chars*$ for any literals that appear in the grammar. We will explicty state these for standard Welkin grammars in the next section.
% TODO: convert this into a table for easy access
% \begin{itemize}
%   \item $::=$ denotes rule assignment,
%   \item \texttt{term ::= $S \subseteq \chars^{*}$} means \texttt{term $\in S$},
%   \item $|$ denotes alternation,
% 	\item In a given choice, an arrow $\to$ denotes a new rule name. For example, the rule
% 		\begin{bnfgrammar}
% 			term ::= `A' $\to$ A | `B' $\to$ B
% 		\end{bnfgrammar}
% 		is equivalent to
% 		\begin{bnfgrammar}
% 			term ::= A || B ;;
% 			A ::= `A' ;;
% 			B ::= `B'
% 		\end{bnfgrammar}
% 	\item \texttt{term*} means 0 or more instances and is shorthand for
% 	\begin{center}
% 		\texttt{terms ::= term terms | term | $\varepsilon$},
% 	\end{center}
% 	\item \texttt{term+} means 1 or most one instances and is shorthand for
% 	\begin{center}
% 		\texttt{terms ::= term terms | term},
% 	\end{center}
%   \item Elements of CHAR* are included in quotes. To avoid confusion, literal quotes are denoted with ['].
% 	\item A production between a terminal and non-terminal, such as $term"A"$, means there is no whitespace character that appears between them. All other productions, in the form \texttt{term1 term2} any number of whitespaces may be included.
% \end{itemize}
\section{The Welkin Language}

There are three fundamental variants of Welkin that define the foundation for the language:
\begin{itemize}
	\item Base Welkin, mirroring the key properties of the core data structure,
	\item Attribute Welkin, extending Base Welkin with attributes. Attributes are a limited type of directive that can customize how the interpreter accepts or presents data,
	\item Binder Welkin, enabling arbitrary evaluation of Welkin files and access to the user's Operating System. This is equivalent to Attribute Welkin with two new directives: \texttt{@eval} and \texttt{@exec}. \end{itemize}
Each of these variants can be parsed with LALR parsers and fundamentally have the same semantics. However, in Binder Welkin, \texttt{@eval} makes the interpreter Turing complete (see Section ?.?), and using \texttt{@exec} can significantly impact the user's system. For this reason, Binder Welkin is a separate, optional component, as detailed in the Section ?.?
% \begin{itemize}
% 	% \item First Define character encodings in general. Helpful reference: \url{https://www.w3.org/International/questions/qa-what-is-encoding}
% 	%       \begin{itemize}
% 	% 	      \item For wide spread use, there should be different character encodings used for \textit{direct comparison} with Welkin files. Ultimately, every Welkin file will be converted into a standard binary (or possibly text) file to store the object
% 	%       \end{itemize}
% 	\item Determine a suitable BNF for Welkin, which can be parsed with LALR (or otherwise a more efficient parser)
% 	      \begin{itemize}
% 		      \item Key goal: make Welkin's syntax fully decidable and efficient to parse. An important component of CFLT called the Semantics Lifting Lemma (TBD) essentially says we can embed a complex syntax into a semantics. (This proof will hopefully be constructive and work for any random syntax, no matter how crazy it might be). In other words, using an efficient parser does NOT limit how expressive Welkin is.
% 		      \item Presuming the result above, there will be two variants: the finite (regex) and full versions.
% 		            \begin{itemize}
% 			            \item The finite, or regex, version is purely for regex-definable files.
% 			            \item The full version will be LALR parsed, as it is generally a standard for programming languages. Not only is it efficient (both in speed and memory), but any grammar written in LALR is unambiguous (reference needed!).
% 			            \item Now that the idea of these two versions is solidifed, we need some common terms. Most of these should come from graphviz, but also in other note taking formats.
% 		            \end{itemize}
% 		      \item The standard format should read just like an ordinary programming language. It may be akin to graphviz, but it should prioritze on the contents of each node and edge, not necessarially how they are rendered. (A better thought would be to put rendering information in a standard \textit{library}, which could then be minimized when browsing through a Welkin file/project.)
% 		            \begin{itemize}
% 			            \item Welkin essentially needs the key elements from set theory: conjunction, disjunction, negation, implication, etc. We can use corresponding symbols for these: $\&\&, ||, \neg, \rightarrow$. In \textit{customizable files}, these symbols can be overloaded and added upon.
% 			            \item Key goal: make this FULLY compatible with dot. (In fact, for a prototype, we can work with dot directly, but we should make it helpful for our needs).
% 									\item Another important point: we want to say that graph ALWAYS refers to a metagraph (to avoid redundancy)		            \end{itemize}
% 	      \end{itemize}
% 	\item Following CFLT, explain a suitable semantics for Welkin.
% 	      \begin{itemize}
% 		      \item We need to determine how to implement all of the axioms.
% 		      \item We also need to use a suitable proof system (e.g., Hilbert, Gentzen, etc.). Maybe that could be decided in CFLT?
% 	      \end{itemize}
% \end{itemize}
% TODO: figure out how to handle references to self. Is a separate keyword 'self' needed?
%\renewcommand{\syntleft}{\normalfont\bfseries}
%\renewcommand{\syntright}{}

% TODO: directly convert this into other grammars, such as lark.
% There should be some consistent procedure to ensure that the BNF here
% is the same as those found in any implementation
% Interesting idea: when there is a node A that should connect to other nodes B_1, B_2, ..., B_n,
% we require that the latter nodes be wrapped in their own graph. That way, we can stay consistent with
% GraphViz notation (for possible compatiblity reasons), but at the same time, we can keep track of the out-neighbors (out going
%\renewcommand{\bnfexpr}{\textbf}
\subsubsection*{Syntax}
Set $\reserved = \{\texttt{\{, \}, ., -, ->, <-}\}.$
% \SetBNFConfig{

%   relation-sym-map = {
%     {::=} = {\ensuremath{=}},
%   }
%   }
% TODO: fix table!
  \begin{table}[htbp]
    \centering
  \begin{tabularx}{\textwidth}{| c | c | c |}
    Variant & Grammar & Notes \\
    \hline
	Base Welkin &
  \begin{bnf}
  terms ::= term*;;
  graph ::= unit? `\{' terms `\}' ;;
  connections ::= term (connector term)+ ;;
	connector ::=
   | `-' term `-' $\to$ edge
   | `-' term `-\>' $\to$ left\_arrow
	 | `<-' term `-' $\to$ right\_arrow ;;
  member ::= unit? (`.'(ident || string)? || `\#'num )+ ;;
	unit ::= ident || string || num ;;
  ident ::= CHAR* ;;
	string ::= STRING ;;
	num ::= NUMBER
\end{bnf}
   & If $\numbers = \emptyset,$ any instance of \texttt{num} should be removed from the parser. \\

 \end{tabularx}
 \end{table}
% relation-sym-map = {
%       {::=} = {\ensuremath{=}}
%	}


	% term ::= graph || connections || member || unit ;;
	% graph ::= unit? `\{' terms `\}' ;;
	% connections ::= term (connector term)+ ;;
	% connector ::= `-' term `-' $\to$ edge
	% | `-' term `->' $\to$ left\_arrow
	% | `<-' term `-' $\to$ right\_arrow ;;
	% member ::= unit? (`.'(ident || string)? || `\#'num )+ ;;
	% unit ::= ident || string || num ;;
	% ident ::= CHAR* ;;
	% string ::= STRING ;;
	% num ::= NUMBER



% TODO: the slashes quotes above should be slashes, and then quotes. We need to fix this!
Base Welkin is given by the grammar in Figure ??. Note that if $\numbers= \emptyset,$ any instances of the rule \texttt{num} must be excluded from the parser. This grammar defines the text-based interface to the Welkin Information Graph (see Subsection 2.? for more details). Recall Rule ?.? that specifices which characters are forbidden in identifiers.
\\ Throughout this document, Welkin documents are formatted with the following convention: the ASCII sequence \texttt{->} is rendered as $\to$ (A graphical user interface may support this rendering via glyphs). % TODO: put special renderings in a table
Attribute Welkin is given in Figure ?.?
% \begin{bnfgrammar}
%   statement ::= (directive || construct || term)* ;;
%   directive ::= `@'.attribute ;;
%   attribute ::= `import' tuple $\to$ import
%   | test ;;
%   construct ::= operator || tuple || list ;;
%   operator ::= ;;
%   tuple ::= ;;
%   list ::=
%  \end{bnfgrammar}
  % TODO: figure out suitable grammar composition notation
Finally, Binder Welkin is given by the BNF in Attribute Welkin composed by two new directives. In BNF, these are appended to the directives rule:
\begin{itemize}
	\item \texttt{eval ::= `eval'.`(' unit `)'},
	\item \texttt{exec ::= `exec'.`(' string `)'}.
\end{itemize}
We explain the semantics for these directives in Section ?.?

% TODO: recognize, in cflt, that the above welkin file is in fact a context free grammar! The more important part, which we need to still define, is the semantics, which will have its full strength with the full grammar. (Maybe we should change that option to be semantics instead?)

\subsubsection*{Semantics}
We break down our semantics first by terms. Directives are handled separately in the next section.
\begin{definition}
Equality of terms.
\begin{itemize}
  \item \textbf{Basis.} Two units are equal if they are the same kind and obey one of the following.
	\begin{itemize}
	  \item \texttt{ident} terms are equal if their corresponding characters are equal,
      \item \texttt{string} terms are equal if their corresponding contents are equal. Thus, \texttt{``A''} coincides with \texttt{'A'},
	  \item \texttt{num} terms are equal if they represent the same value. Thus, \texttt{1} coincides with \texttt{10E}.
	\end{itemize}
  \item \textbf{Recursion.}
		\begin{itemize}
		  \item Equality of connectors
				\begin{itemize}
				  \item
				  \item
				  \item \texttt{edge} terms are equal if they correspond as both left and right arrows.
				\end{itemize}

		  \item Two connections are equal if they connect the same terms and have equal connectors.
		  \item Two graphs are equal if they contain the same terms.
	\end{itemize}

\item
\end{itemize}
\end{definition}
A \textbf{scope} is recursively defined and intutively is a level of terms.
\begin{definition} (Scope)
 Let $t$ be a term.
  \begin{itemize}
	\item If $t$ is not contained in a graph, then $\scope(\texttt{term}) = 0,$
	\item If $G' \in G$ are both graphs and $\scope(G') = n,$ then for all $t \in G',$ $\scope(t) = \scope(G) + 1.$
\end{itemize}
\end{definition}
A \textbf{valid} base Welkin file consists satisfies a unique naming rule: in every scope, there are no name collisons. In particular, every graph must \textbf{only be defined once.} Note that, by the way equality was defined between two numbers,
  there can only be one representation of a given number in a scope. For example, using $1$ and $10*E^{-1}$ in the same scope would produce a name collison.
\\ We first form an Abstract Syntax Tree (AST), from which we form the final stored data in a \textbf{Welkin Information Graph.}
\begin{definition}
  Base Welkin is parsed into the following AST $\mathcal{A}.$
  \begin{itemize}
	\item Every term is a new subtree with its contents as children.
    \item Every graph is an ordered pair of its aliases and list of children.
    \item Every connection is an ordered pair:
		  \begin{itemize}
			\item Left arrows $u - a \to v$ correspond to a triple $(u, a, v);$
			\item Right arrows $u \leftarrow a - v$ correspond to the triple $(v, a, u);$
			\item Edges correspond to both a left and right arrow.
		  \end{itemize}
	\item Every unit is converted into its corresponding encoding via $\encoding^{*}.$
  \end{itemize}
 \end{definition}
% TODO: talk about encoding of numbers. This probably a separate encoding from the one used to write the welkin file
\begin{definition}
	A \textbf{Welkin Information Graph (WIG)} $\mathcal{G}$ consists of
  \begin{itemize}
    \item sets $G_{0}, G_{1}, \cdots, G_{n}$ of \textbf{layers},
    \item for each $0 \leq k \leq n,$ functions $s_{k}, t_{k}: G_{k+1} \to G_{k}$ called the $i$-th $\textbf{source}$ and $\textbf{target}$ maps, respectively,
    \item for each $k,$ an injective function $i_{k}: G_{k} \to G_{k+1},$
    \item a set $\mathcal{L}$ of \textbf{labels} or \textbf{aliases}, and
    \item for each $k,$ an injective function $l_{k}: \mathcal{L} \to G_{k}$ called the $k$-th \textbf{labeling map,}
  \end{itemize}
  that obey the following equations:
  \begin{itemize}
    \item $s_{k} \circ s_{k+1} = s_{k} \circ t_{k+1}$
    \item $t_{k} \circ s_{k+1} = t_{k} \circ t_{k+1}$
    \item $s_{k} \circ i_{k} = \textrm{id} = t_{k} \circ i_{k} $
    \item (Condition to allow edges to be the ``intervals'' of connectors)
  \end{itemize}
  We may illustrate the above definition via the following diagram.
\end{definition}
% Cite: WIGs are a special form of reflexive n-graphs, or n-globular sets. We add the labeling function to
% store a record of labels from a previous Welkin file, and the last property is used to distinguish internal arcs from
% connectors
Notice that not every vertex or edge in a WIG have an alias, as opposed to a colored graph. There are several examples demonstrating that, under a suitable transformation, a normalized WIG may contain new structures not found in a Welkin file. See Example ??.

To select a single graph from a layer, we use the following definition.
\begin{definition} (Abstract version of graphs) ...
\end{definition}
\begin{lemma}
The conversion from ASTs to Welkin Information Graphs is valid.
\end{lemma}
The final output of parsing is a normalized WIG. We define Welkin Canonical Form in the following fashion.
\begin{definition}
A WIG is in \textbf{Welkin Canonical Form (WCF)} if ...
\end{definition}
Based on this form, we have chosen a unique way to represent Welkin files. In particular, there is a representation under WIG (generalized) homotopies. We prove that there is a polynomial (or exponential?) algorithm to convert any WIG into WNF.

\section{General Application Behavior}

Note that all apparent structures may be adjusted under cryptomorphism.
\subsubsection*{Directives}
Each directive relies on the following components.
\begin{itemize}
  \item Parser: takes in a Welkin file and generates an AST,
  \item Validator: ensures that the AST is valid, raising an error that directly points to a violation,
  \item From here, an AST may be processed by three different means:
		\begin{itemize}
		  \item Recorder: takes the AST, converts it into a WIG in WCF, serializes the data,
		  \item Attributor: %TODO: change name!
		  \item Binder:
		\end{itemize}
\end{itemize}
\begin{center}
  \begin{tabular}{| c | c | c |}
	Directive & Definition & Example \\
	\hline
	\texttt{import} & Concatenates the file & Example

  \end{tabular}
\end{center}




\subsection{Customization}
All Welkin files are infinitely customizable via the welkin config file, which is written in Attribute Welkin. Any attribute can be used, and other Welkin files can be imported. A base config file is required to customize a Welkin grammar. From there, configs can be arbitrarily nested to create and connect any desired (context-free) grammar, validator, and displayer.
t has the following format:
% TODO: replace itemzie with listing
% TODO: decide how to work with a folder (or folders) of config files
\begin{itemize}
	\item Encoding
				\begin{itemize}
					% TODO: list major ascii versions/varieties. Need an official reference for this!
					\item Options: ascii, utf-8, utf-16, other
					\item In the case of other: we need to specify how to define an encoding. (We need a light-weight API for implementations)
				\end{itemize}
	\item Grammar
				\begin{itemize}
					\item Strength: bounded (only finitely nested graphs with a given nesting limit, no recursion), no-self (arbitrary nesting limit, but no recursion), full (recursion allowed)
					\item Customized: use a builtin template or custom welkin file. These can be used to change any part of the grammar, including adding keywords, the symbols used, adding new symbols, etc. Essentially, this will be a way to built new grammars from the original specification; we will need a separate parser for this (i.e., a parser of BNF/Welkin accepted notation).
				\end{itemize}

	\item (Optional) Language
				\begin{itemize}
					\item Defaults to English. Can be written in the writer's desired language (as long as it has been configured in Encoding above)
				\end{itemize}
\end{itemize}

subsubsection*{Attribute Welkin}

In Welkin, we informally write the BNF above as follows:
% TODO: explain unit notation (as it maybe clearer than the recursion below). In other words, mark arbitrary variables with the keyword unit
% TODO: decide whether to introduce another arrow symbol for custom grammars.
% While we have imposed few to no restrictions on custom grammars (besides being LALR), it may be the case
% that multiple people want to use => for their own purpose. Is there a convenient way we can do this?
\begin{quote}{\ttfamily \raggedright \noindent
	term -> \{ graph connection ident string\}\\
	graph -> \{\{ident \{\}\}->`\{'--term--`\}'\}\\
	connection -> \{term--connector--term\}\\
	connector -> \{edge arrow\}\\
	edge -> `--'\\
	arrow -> `->'\\
	ident -> CHAR*\\
	string -> ``'' CHAR* ``'' | `\`' CHAR* `\''
}\end{quote}

\section{Core Algorithms}

\subsection{Graph Encoding}



\label{ch:spec}
