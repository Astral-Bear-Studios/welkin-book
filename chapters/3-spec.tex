% SPDX-FileCopyrightText: 2023 Oscar Bender-Stone <oscarbenderstone@gmail.com>
% SPDX-License-Identifier: CC-BY-4.0
% 4-spec.tex - Specifices the Welkin language and provides a theoretical framework
% for general implementations


\chapter{The Welkin Standard}

\section{Preliminaries}

% Helpful macros for terms for character encoding in math mode
\newcommand*{\chars}{\mathrm{CHAR}}
\newcommand*{\bytes}{\mathrm{BYTES}}
\newcommand*{\numbers}{\mathrm{NUMBER}}
\newcommand*{\strings}{\mathrm{STRING}}
\newcommand*{\term}{\mathrm{term}}
\newcommand*{\terms}{\mathrm{terms}}
\newcommand*{\delimiters}{\mathrm{DELIMITERS}}
\newcommand*{\encoding}{\mathcal{E}}

\subsection{Character Encodings}
% TODO: generalize to byte encodings and numbers.
In a formalist fashion, our BNF variant leaves encodings as an generalized notion. Let Char be an arbitrary, finite set.
An \textbf{encoding} is a mapping $\encoding : \mathbb{N} \to \chars.$
We denote $\chars = \encoding(\chars)$ and CHAR* as the Kleene-closure of CHAR. We also recognize a distinguished (possibly empty) subimage $\numbers \subset \chars.$ %TODO: describe this in more detail
\\ Character encodings may be given as finite tables. Several major encodings are formally defined in the following sources.
\begin{itemize}
	\item ASCII []
	\item UTF-8 []
	\item UTF-16 []
\end{itemize}
As an auxiliary set, define
\begin{align*}
	\strings(\delimiters) = \{s \in \chars^{*}\;|\; s = d_{1} u d_{2}, u \in (\chars\} \setminus \delimiters)^{*}\},\end{align*}
where $\delimiters \subset \chars^{2}.$
Strings may include their delimiters by escaping them, i.e., using a sufficient prefix or suffix to distinguish them from string boundaries. Any Welkin implementations may choose how to escape their strings by explicitly setting the (default) DELIMITERS. For the rest of this document, we will denote $\strings ::= \strings(\delimiters)$.
\\ We implicitly assume that $CHAR*$ does not conflict with literals defined in a given grammar, and that these literals can be escaped with a character $ESCAPE.$. Setting $ESCAPE = \varepsilon,$ means there is no way to include predefined literals in CHAR.

\subsection{EBNF Variant}
Our variant of EBNF uses the following notation:
% TODO: convert this into a table for easy access
\begin{itemize}
  \item $::=$ denotes rule assignment,
  \item \texttt{term ::= $S \subseteq \chars^{*}$} means \texttt{term $\in S$},
  \item $|$ denotes alternation,
	\item In a given choice, an arrow $\to$ denotes a new rule name. For example, the rule
		\begin{bnfgrammar}
			term ::= `A' $\to$ A | `B' $\to$ B
		\end{bnfgrammar}
		is equivalent to
		\begin{bnfgrammar}
			term ::= A || B ;;
			A ::= `A' ;;
			B ::= `B'
		\end{bnfgrammar}
	\item \texttt{term*} means 0 or more instances and is shorthand for
	\begin{center}
		\texttt{terms ::= term terms | term | $\varepsilon$},
	\end{center}
	\item \texttt{term+} means 1 or most one instances and is shorthand for
	\begin{center}
		\texttt{terms ::= term terms | term},
	\end{center}
  \item Elements of CHAR* are included in quotes. To avoid confusion, literal quotes are denoted with ['].
	\item A production between a terminal and non-terminal, such as $term"A"$, means there is no whitespace character that appears between them. All other productions, in the form \texttt{term1 term2} any number of whitespaces may be included.
\end{itemize}

% \begin{itemize}
% 	\item While there is an ISO standard for EBNF, several authors have noted it has issues. References: \url{https://dwheeler.com/essays/dont-use-iso-14977-ebnf.html}, \url{https://www.grammarware.net/text/2012/bnf-was-here.pdf}. As recommended by David Wheeler in the first reference, we use the BNF Notation defined in the W3 standard (at \url{https://www.w3.org/Notation.html}).
% \end{itemize}
\section{The Welkin Language}

There are three fundamental variants of Welkin that define the foundation for the language:
\begin{itemize}
	\item Base Welkin, a language mirroring the key properties of the core data structure;
	\item Standard Welkin, which extends Base Welkin with attributes. Attributes are a limited type of directive that can customize how the interpreter accepts or presents data;
	\item Binder Welkin, which enables arbitrary evaluation of Welkin files and access to Operating System resources. This is equivalent to Attribute Welkin with two new directives: $@eval$ and $@exec.$ See Section ?.? for more details.
\end{itemize}
Each of these variants can be parsed with LALR parsers and fundamentally have the same semantics. However, the third requires the highest level of privileges and, as proven in Section ?.?, makes the interperter Turing complete. All official implementations will include Binder Welkin as a separate, optional component.
% \begin{itemize}
% 	% \item First Define character encodings in general. Helpful reference: \url{https://www.w3.org/International/questions/qa-what-is-encoding}
% 	%       \begin{itemize}
% 	% 	      \item For wide spread use, there should be different character encodings used for \textit{direct comparison} with Welkin files. Ultimately, every Welkin file will be converted into a standard binary (or possibly text) file to store the object
% 	%       \end{itemize}
% 	\item Determine a suitable BNF for Welkin, which can be parsed with LALR (or otherwise a more efficient parser)
% 	      \begin{itemize}
% 		      \item Key goal: make Welkin's syntax fully decidable and efficient to parse. An important component of CFLT called the Semantics Lifting Lemma (TBD) essentially says we can embed a complex syntax into a semantics. (This proof will hopefully be constructive and work for any random syntax, no matter how crazy it might be). In other words, using an efficient parser does NOT limit how expressive Welkin is.
% 		      \item Presuming the result above, there will be two variants: the finite (regex) and full versions.
% 		            \begin{itemize}
% 			            \item The finite, or regex, version is purely for regex-definable files.
% 			            \item The full version will be LALR parsed, as it is generally a standard for programming languages. Not only is it efficient (both in speed and memory), but any grammar written in LALR is unambiguous (reference needed!).
% 			            \item Now that the idea of these two versions is solidifed, we need some common terms. Most of these should come from graphviz, but also in other note taking formats.
% 		            \end{itemize}
% 		      \item The standard format should read just like an ordinary programming language. It may be akin to graphviz, but it should prioritze on the contents of each node and edge, not necessarially how they are rendered. (A better thought would be to put rendering information in a standard \textit{library}, which could then be minimized when browsing through a Welkin file/project.)
% 		            \begin{itemize}
% 			            \item Welkin essentially needs the key elements from set theory: conjunction, disjunction, negation, implication, etc. We can use corresponding symbols for these: $\&\&, ||, \neg, \rightarrow$. In \textit{customizable files}, these symbols can be overloaded and added upon.
% 			            \item Key goal: make this FULLY compatible with dot. (In fact, for a prototype, we can work with dot directly, but we should make it helpful for our needs).
% 									\item Another important point: we want to say that graph ALWAYS refers to a metagraph (to avoid redundancy)		            \end{itemize}
% 	      \end{itemize}
% 	\item Following CFLT, explain a suitable semantics for Welkin.
% 	      \begin{itemize}
% 		      \item We need to determine how to implement all of the axioms.
% 		      \item We also need to use a suitable proof system (e.g., Hilbert, Gentzen, etc.). Maybe that could be decided in CFLT?
% 	      \end{itemize}
% \end{itemize}
% TODO: figure out how to handle references to self. Is a separate keyword 'self' needed?
%\renewcommand{\syntleft}{\normalfont\bfseries}
%\renewcommand{\syntright}{}

% TODO: directly convert this into other grammars, such as lark.
% There should be some consistent procedure to ensure that the BNF here
% is the same as those found in any implementation
% Interesting idea: when there is a node A that should connect to other nodes B_1, B_2, ..., B_n,
% we require that the latter nodes be wrapped in their own graph. That way, we can stay consistent with
% GraphViz notation (for possible compatiblity reasons), but at the same time, we can keep track of the out-neighbors (out going
%\renewcommand{\bnfexpr}{\textbf}
\subsubsection*{Syntax}
\begin{bnfgrammar}
	terms ::= term* ;;
	term ::= graph || connections || member || unit ;;
	graph ::= unit? `\{' terms `\}' ;;
	connections ::= term (connector term)+ ;;
	connector ::= `-' term `-' $\to$ edge
	| `-' term `->' $\to$ left\_arrow
	| `<-' term `-' $\to$ right\_arrow ;;
	member ::= unit? (`.'(ident || string)? || `\#'num)+ ;;
	unit ::= ident || string || num ;;
	ident ::= CHAR* ;;
	string ::= STRING ;;
	num ::= NUMBER
\end{bnfgrammar}
% TODO: the slashes quotes above should be slashes, and then quotes. We need to fix this!
Base Welkin is given by the grammar in Figure ??. Note that if $\numbers= \emptyset,$ any instances of the rule \texttt{num} must be excluded from the parser. This grammar defines the text-based interface to the Welkin Information Graph (see Subsection 2.? for more details). Implicitly while parsing, we enforce the fact that all identifiers may not solely contain the symbols \texttt{{}, ., -, ->.} We enforce this by matching these symbols first.
\\ Throughout this document, Welkin documents are formatted with the following convention: the ASCII sequence \texttt{->} is rendered as $\to$ (A graphical user interface may support this rendering via glyphs). % TODO: put special renderings in a table

% TODO: recognize, in cflt, that the above welkin file is in fact a context free grammar! The more important part, which we need to still define, is the semantics, which will have its full strength with the full grammar. (Maybe we should change that option to be semantics instead?)

\subsubsection*{Semantics}
A \textbf{scope} is recursively defined and intutively is a level of terms. A \textbf{valid} base Welkin file consists satisfies a unique naming rule: in every scope, there are no name collisons. In particular, every graph must \textbf{only be defined once.}
\\ We first form an Abstract Syntax Tree (AST), from which we form the final stored data in a \textbf{Welkin Information Graph.}
\begin{definition}
  Base Welkin is parsed into the following AST $\mathcal{A}.$
  \begin{itemize}
	\item Every term is a new subtree with its contents as children.
    \item Every graph is an ordered pair of its aliases and list of children.
    \item Every connection is an ordered pair:
		  \begin{itemize}
			\item Left arrows $u \to v$ correspond to a pair $(u,v);$
			\item Right arrows $u \leftarrow v$ correspond to the pair $(v, u);$
			\item Edges correspond to both a left and right arrow.
		  \end{itemize}
	\item Every atom is converted into its corresponding encoding via the function $\mathcal{B} : \chars \to \bytes$
\end{itemize}
 \end{definition}
% TODO: talk about encoding of numbers. This probably a separate encoding from the one used to write the welkin file
\begin{definition}
	A \textbf{Welkin Information Graph (WIG)} is a tuple $G = (V, E, A),$ where
	\begin{itemize}
		\item $V$ is a set of \textbf{vertices} or \textbf{units,}
		\item $E \subseteq V^{2} $ is a set of \textbf{(directed) edges,}
		\item $A: \chars* \to V \cup E$ is an \textbf{alias function.}
	\end{itemize}
  \end{definition}
  Notice that not every vertex or edge in a WIG have an alias, as opposed to a colored graph. There are several examples demonstrating that, under a suitable transformation, a normalized WIG may contain new structures not found in a Welkin file. See Example ??.
\begin{lemma}
The conversion from ASTs to Welkin Information Graphs is valid.
\end{lemma}
The final output of parsing is a normalized WIG. We define Welkin Normal Form in the following fashion.
\begin{definition}
A WIG is in \textbf{Welkin Normal Form (WNF)} if ...
\end{definition}
Based on this form, we have chosen a unique way to represent Welkin files. In particular, there is a representation under WIG (generalized) homotopies. We prove that there is a polynomial (or exponential?) algorithm to convert any WIG into WNF.

\section{General Application Behavior}


\subsection{Customization}
All Welkin files are infinitely customizable via the welkin config file, which is written in standard welkin.

Every .welkin file has a corresponding configuration. It may either be put as a comment or (preferred) written in a separate file, which, by default, is called config.welkin. It has the following format:
% TODO: replace itemzie with listing
% TODO: decide how to work with a folder (or folders) of config files
\begin{itemize}
	\item Encoding
				\begin{itemize}
					% TODO: list major ascii versions/varieties. Need an official reference for this!
					\item Options: ascii, utf-8, utf-16, other
					\item In the case of other: we need to specify how to define an encoding. (We need a light-weight API for implementations)
				\end{itemize}
	\item Grammar
				\begin{itemize}
					\item Strength: bounded (only finitely nested graphs with a given nesting limit, no recursion), no-self (arbitrary nesting limit, but no recursion), full (recursion allowed)
					\item Customized: use a builtin template or custom welkin file. These can be used to change any part of the grammar, including adding keywords, the symbols used, adding new symbols, etc. Essentially, this will be a way to built new grammars from the original specification; we will need a separate parser for this (i.e., a parser of BNF/Welkin accepted notation).
				\end{itemize}

	\item (Optional) Language
				\begin{itemize}
					\item Defaults to English. Can be written in the writer's desired language (as long as it has been configured in Encoding above)
				\end{itemize}
\end{itemize}

Alternatively, a file with a different name may be used; see th


\begin{itemize}
	\item Current problem: we need a way to recognzie which Welkin modules (graphs) define grammars. (Then we can figure out how one can customize \textit{any} aspect of Welkin). Here are some possible solutions (and evaluations thereof):
				\begin{itemize}
					\item Introduce a new meta-arrow \texttt{=>} designed specifically to be detected by Welkin (the left hand side denotes any terms in the user file; the right hand side must be terms that are defined by the Welkin interface). Using this symbol may initially work, but what if a user would like to use this meta-arrow in their grammar? How do we control how much the meta-arrow is used? I feel as though this could be dangerous, if not managed. Moreover, logistically, \textit{how} do we inform users of the terms they may bind to? For example, in the long-term, how do we make it clear that there is a ident for, say, num (standing in for general int/float)?
					\item Create a different welkin file, such as welkin.config, that only uses minimal syntax (or a slightly extended version). This would ensure that there is a distinction between the information in welkin files and the grammars that they utilize. However, we want to makek Welkin infinitely customizable, so I aim not to use this solution, if at all possible.
					\item Preferred, but still in the works: bootstrap interfaces. We would probably want to add this subsection later on, but definitely mention it while customizing grammars. \textit{Actually, customizing grammars is NOT a part of the standard, but rather, it is a part of the API. We will include EBNF and the custom grammar for standard Welkin}
				  \item I am aiming to use the last solution, but what should the standard Welkin language be? Should it be aimed for programmers? Should it be aimed for general information preservation?
				\end{itemize}
	\item At this point, I believe I am aiming to use the first solution; it would be benefitcial for Welkin itself to intrepret what Welkin files do, not \textit{directly} the other way around. At its core, Welkin files store information; it is up to an external program (such as Welkin) to figure out \textit{how} those files may be interpreted.
				\begin{itemize}
					\item Moreover, doing the other way around directly would prove formally difficult. For correctness, we would have to worry about having a correct model for C, the operating system, etc.. But, part of this project is building the infrastructure for \textit{getting and organizing} that specification! For initial implementations, Welkin need not \textit{have} a low-level specification, so neither should this standard. That should be taken care of in a formally verified programming language (or formally verified binaries).
					\item I hope that using the meta arrow could be optional in time; there could easily be ambigiuity if
								care is not taken. For example, the rule (test1 -> test2 -> graph) is ambiguous because of the ordering of the parantheses; it is unclear what is ultimately turned into a rule.
					\item However, if the lefthand side only uses terms in the minimal grammar, this would not be ambigiuous. That could certainly work. Regardless, \textit{we need to make it clear HOW Welkin, the program, is involved. Using the meta arrow is probably the least intrustive way to go about this, and can easily be customized by the user.}
				\end{itemize}

  \item Rephrasing above problem: how do we make it clear when we are defining a new semantics?
		\begin{itemize}
		  \item A key realization: Welkin \textit{is a semantics language.} You can define anything in it! It suffices to show that we can embed Welkin into discrete foci (or, more directly, can define any Chomsky grammars. This part is pretty clear from the semantics given to base welkin (or for graphs, and for connections, not for a reference to self + ?))
		  \item We could try making code blocks that specifically contain bindings. This would be a fancier alternative to restricting names (or coming up with a system, such as names prefixed with $_{}$). My hesitance to go with this solution is flexibility; should we force the users to do this?
		  \item Here is a possible question we can ask: how do we distinguish between regular and \textit{interfaced} Welkin?
		  \item The goal is to have the \textit{guest} tackle how to interpret Welkin... but we still want to put the guest in Welkin!
				\begin{itemize}
				  \item How do we gain ``awareness'' about Welkin's interfaces?
				  \item We need a place to talk about \textit{interpretations.} We know Welkin can talk about it, but how do we \textbf{reference external things? (Files, programs, even a simple microcontroller?)}
						\begin{itemize}
						  \item Do we directly include a pointer to the file? Is that strictly necessary8? It could definitely break on different machines. We would have to keep some config data in mind.
						  \item We know that any possible import symbols, as per compiler theory (and general humanb comprehension) need to be applied directlyat the \textit{top} of a page. But how do we define the import statement itself?
						  \item Can we bootstrap an interface mechanism?
						\end{itemize}
				\end{itemize}
		\end{itemize}

  \item Current (recommended) solution: we define standard Welkin to have direct access to the interpreter, similar to prolog. \textit{Later on, we will make it clear that standard Welkin can be queries, but can do more.} Ultimately, \textit{it is up to the individual to decide whether they include programming elements into their own welkin files. This is the key thing! } All the user needs to do is define their EBNF in standard Welkin
		\begin{itemize}
		  \item Here's a big idea: we can go back and \textit{refine} the base interface through standard Welkin! That's the powerful of Welkin, after all!
		  \item More precisely, we need to implement Vero, the Welkin interface for stating and verifying formal properties. \textit{We only want to make this through the APIs specified by Welkin. The implementation should NEVER matter for verification.}
		  \item There should be a separate document outling the thought process behind Vero, but for the most part, Vero should be defined \textit{with Welkin alone.} It will be the big first test for Welkin to make sure Welkin's claim for any layer of abstraction works well.
		\item Vero comes with its own grammar which is fully customizable (some mathematicians/logicians/etc may want to change it, for their personal preference). We also have certain semantics that impose checks on graphs. This is the key thing here: \textit{we want to make checks/formal properties explicit.}
		  \item Main takeaway: \textit{the interface can always be defined first. It need not be perfect. We can start with any interface and clarify it with Welkin. We can delete things, but we NEVER have to. We can add onto it instead}
		  \item Moreover, using standard Welkin for \textit{all implementations} is a good sanity check; how can we check different configs with completely different grammars! At some point, \textit{ we need to use the same language to customize things!} Starting with this idea, it is straight forward to make custom interpreter settings \textit{in your own language.} You just have to invoke it in standard welkin at some point.
				\begin{itemize}
				  \item In fact, some core plugins will use this idea as well! One of the big things to have is a suitable \textit{build system.} That will be included and have a straightforward interface.
				  \item Other key starter grammars include: bullets (for bullet point type notes) and literate (for a starting point with code blocks). (As an implementation detail, these should be \textit{optional} packages the user can be install; they should be more straightforward to get setup)
				\end{itemize}
		\end{itemize}


\end{itemize}

In Welkin, we informally write the BNF above as follows:
% TODO: explain unit notation (as it maybe clearer than the recursion below). In other words, mark arbitrary variables with the keyword unit
% TODO: decide whether to introduce another arrow symbol for custom grammars.
% While we have imposed few to no restrictions on custom grammars (besides being LALR), it may be the case
% that multiple people want to use => for their own purpose. Is there a convenient way we can do this?
\begin{quote}{\ttfamily \raggedright \noindent
	term -> \{ graph connection ident string\}\\
	graph -> \{\{ident \{\}\}->`\{'--term--`\}'\}\\
	connection -> \{term--connector--term\}\\
	connector -> \{edge arrow\}\\
	edge -> `--'\\
	arrow -> `->'\\
	ident -> CHAR*\\
	string -> ``'' CHAR* ``'' | `\`' CHAR* `\''
}\end{quote}

\section{Core Algorithms}

\subsection{Graph Encoding}



\label{ch:spec}
